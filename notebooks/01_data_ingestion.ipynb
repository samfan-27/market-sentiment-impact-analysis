{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec78b46b",
   "metadata": {
    "id": "ec78b46b"
   },
   "source": [
    "# Phase 1b: Data Ingestion & Schema Harmonization\n",
    "\n",
    "## Objective\n",
    "\n",
    "Transform raw, messy text and external API data into two clean, separate datasets:\n",
    "\n",
    "1. **`daily_news_cleaned.csv`**: A harmonized list of unique news events with standardized timestamps\n",
    "2. **`stock_returns_60.csv`**: A clean record of log-returns for the 60 target stocks, preserving sector and beta metadata\n",
    "\n",
    "## Data Quality Challenges\n",
    "\n",
    "Each news source has distinct irregularities that must be handled individually:\n",
    "\n",
    "| Source | Issues | Solutions |\n",
    "|--------|--------|----------|\n",
    "| **CNBC** | Empty rows, \"ET\" timezone noise, verbose date format | Drop NaN rows, strip timezone, parse datetime |\n",
    "| **Guardian** | No description column, `\\n\\n` in text, DMY format | Fill empty descriptions, clean newlines, parse DMY |\n",
    "| **Reuters** | Clean format (minimal issues) | Direct date parsing (MMM DD YYYY) |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdc5e1f",
   "metadata": {
    "id": "2fdc5e1f"
   },
   "source": [
    "## 1. Setup: Imports and Path Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd1cbc18",
   "metadata": {
    "executionInfo": {
     "elapsed": 3569,
     "status": "ok",
     "timestamp": 1770952263616,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "fd1cbc18"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "EnvcdMrImiLt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16248,
     "status": "ok",
     "timestamp": 1770952279869,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "EnvcdMrImiLt",
    "outputId": "b757b37d-1894-450c-8ad2-326d967f017e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cba6c0e9",
   "metadata": {
    "executionInfo": {
     "elapsed": 632,
     "status": "ok",
     "timestamp": 1770952280505,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "cba6c0e9"
   },
   "outputs": [],
   "source": [
    "project_root = '/content/drive/MyDrive/market-sentiment-impact-analysis'\n",
    "\n",
    "data_raw = os.path.join(project_root, 'data', 'raw')\n",
    "data_processed = os.path.join(project_root, 'data', 'processed')\n",
    "data_tickers = os.path.join(project_root, 'data', 'tickers')\n",
    "\n",
    "os.makedirs(data_raw, exist_ok=True)\n",
    "os.makedirs(data_processed, exist_ok=True)\n",
    "os.makedirs(data_tickers, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1Wy0lG9zngvX",
   "metadata": {
    "id": "1Wy0lG9zngvX"
   },
   "source": [
    "---\n",
    "\n",
    "## 2. News Ingestion & Specific Schema Mapping\n",
    "\n",
    "Each news source requires individual processing due to distinct data quality issues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IPtQppGfnz2L",
   "metadata": {
    "id": "IPtQppGfnz2L"
   },
   "source": [
    "### 2.1 CNBC Data Processing\n",
    "\n",
    "**Input Schema**: `Headlines`, `Time`, `Description`\n",
    "\n",
    "**Data Irregularities**:\n",
    "- Empty rows (`,,` patterns)\n",
    "- Timezone noise: `\"7:51 PM ET Fri, 17 July 2020\"` contains \"ET\" and day names\n",
    "- Verbose date format requiring custom parsing\n",
    "\n",
    "**Action Plan**:\n",
    "1. Load CSV, drop fully empty rows\n",
    "2. Strip \" ET\" from time strings\n",
    "3. Parse datetime with custom logic\n",
    "4. Rename columns to standard schema\n",
    "5. Add source tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3FpFpcoZpS0l",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 692,
     "status": "ok",
     "timestamp": 1770952281199,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "3FpFpcoZpS0l",
    "outputId": "4a362885-553a-4465-df37-12cb3ff176bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CNBC data from /content/drive/MyDrive/market-sentiment-impact-analysis/data/raw/cnbc_headlines.csv\n",
      "Initial shape: (3080, 3)\n",
      "\n",
      "First 5 rows:\n",
      "                                           Headlines                            Time                                        Description\n",
      "0  Jim Cramer: A better way to invest in the Covi...   7:51  PM ET Fri, 17 July 2020  \"Mad Money\" host Jim Cramer recommended buying...\n",
      "1     Cramer's lightning round: I would own Teradyne   7:33  PM ET Fri, 17 July 2020  \"Mad Money\" host Jim Cramer rings the lightnin...\n",
      "2                                                NaN                             NaN                                                NaN\n",
      "3  Cramer's week ahead: Big week for earnings, ev...   7:25  PM ET Fri, 17 July 2020  \"We'll pay more for the earnings of the non-Co...\n",
      "4  IQ Capital CEO Keith Bliss says tech and healt...   4:24  PM ET Fri, 17 July 2020  Keith Bliss, IQ Capital CEO, joins \"Closing Be...\n",
      "\n",
      "Column names: ['Headlines', 'Time', 'Description']\n"
     ]
    }
   ],
   "source": [
    "cnbc_path = os.path.join(data_raw, 'cnbc_headlines.csv')\n",
    "\n",
    "print(f'Loading CNBC data from {cnbc_path}')\n",
    "cnbc_raw = pd.read_csv(cnbc_path)\n",
    "\n",
    "print(f'Initial shape: {cnbc_raw.shape}')\n",
    "print('\\nFirst 5 rows:')\n",
    "print(cnbc_raw.head())\n",
    "print(f'\\nColumn names: {list(cnbc_raw.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "qMq2e05-qFSh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1770952281202,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "qMq2e05-qFSh",
    "outputId": "5528da9b-c64f-4f62-b2af-f1fd8bc98573"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 280 completely empty rows\n",
      "Shape after cleaning: (2800, 3)\n"
     ]
    }
   ],
   "source": [
    "# Drop completely empty rows\n",
    "cnbc_clean = cnbc_raw.dropna(how='all')\n",
    "\n",
    "rows_removed = len(cnbc_raw) - len(cnbc_clean)\n",
    "print(f'Removed {rows_removed} completely empty rows')\n",
    "print(f'Shape after cleaning: {cnbc_clean.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3w29_urGqoR3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1770952281229,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "3w29_urGqoR3",
    "outputId": "4834d08a-ce12-40bc-f344-8af5dfcd61b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of cleaned timestamps:\n",
      "                             Time                 Time_Cleaned\n",
      "0   7:51  PM ET Fri, 17 July 2020   7:51  PM Fri, 17 July 2020\n",
      "1   7:33  PM ET Fri, 17 July 2020   7:33  PM Fri, 17 July 2020\n",
      "3   7:25  PM ET Fri, 17 July 2020   7:25  PM Fri, 17 July 2020\n"
     ]
    }
   ],
   "source": [
    "# Clean the Time colum, remove \" ET\" timezone marker\n",
    "# Example: \"7:51  PM ET Fri, 17 July 2020\" -> \"7:51  PM Fri, 17 July 2020\"\n",
    "\n",
    "def clean_cnbc_time(time_str):\n",
    "    if pd.isna(time_str):\n",
    "        return time_str\n",
    "    cleaned = str(time_str).replace(' ET', '')\n",
    "    return cleaned\n",
    "\n",
    "cnbc_clean['Time_Cleaned'] = cnbc_clean['Time'].apply(clean_cnbc_time)\n",
    "\n",
    "print('Sample of cleaned timestamps:')\n",
    "print(cnbc_clean[['Time', 'Time_Cleaned']].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6lqY2M-Wrwgf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 969,
     "status": "ok",
     "timestamp": 1770952282205,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "6lqY2M-Wrwgf",
    "outputId": "a3c76c55-c95b-43f5-dc82-951a125d0717"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date parsing results:\n",
      "Successfully parsed: 2800\n",
      "Failed to parse: 0\n",
      "\n",
      "Sample parsed dates:\n",
      "                  Time_Cleaned                date\n",
      "0   7:51  PM Fri, 17 July 2020 2020-07-17 19:51:00\n",
      "1   7:33  PM Fri, 17 July 2020 2020-07-17 19:33:00\n",
      "3   7:25  PM Fri, 17 July 2020 2020-07-17 19:25:00\n",
      "4   4:24  PM Fri, 17 July 2020 2020-07-17 16:24:00\n",
      "5   7:36  PM Thu, 16 July 2020 2020-07-16 19:36:00\n"
     ]
    }
   ],
   "source": [
    "# Parse datetime\n",
    "\n",
    "def parse_cnbc_datetime(time_str):\n",
    "    if pd.isna(time_str):\n",
    "        return pd.NaT\n",
    "    try:\n",
    "        return pd.to_datetime(time_str, format='mixed', utc=False)\n",
    "    except:\n",
    "        return pd.NaT\n",
    "\n",
    "cnbc_clean['date'] = cnbc_clean['Time_Cleaned'].apply(parse_cnbc_datetime)\n",
    "\n",
    "print('Date parsing results:')\n",
    "print(f'Successfully parsed: {cnbc_clean['date'].notna().sum()}')\n",
    "print(f'Failed to parse: {cnbc_clean['date'].isna().sum()}')\n",
    "print('\\nSample parsed dates:')\n",
    "print(cnbc_clean[['Time_Cleaned', 'date']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "nOsPOoz9ubUN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1770952282209,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "nOsPOoz9ubUN",
    "outputId": "4bd4edcb-3478-460a-cae5-138b099a1cb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNBC standardized shape: (2800, 4)\n",
      "\n",
      "Columns: ['date', 'headline', 'description', 'source']\n",
      "\n",
      "Sample:\n",
      "                 date                                           headline                                        description source\n",
      "0 2020-07-17 19:51:00  Jim Cramer: A better way to invest in the Covi...  \"Mad Money\" host Jim Cramer recommended buying...   CNBC\n",
      "1 2020-07-17 19:33:00     Cramer's lightning round: I would own Teradyne  \"Mad Money\" host Jim Cramer rings the lightnin...   CNBC\n",
      "3 2020-07-17 19:25:00  Cramer's week ahead: Big week for earnings, ev...  \"We'll pay more for the earnings of the non-Co...   CNBC\n"
     ]
    }
   ],
   "source": [
    "# Schema standardization\n",
    "# Time -> date, Headlines -> headline, Description -> description\n",
    "# Add: source = \"CNBC\"\n",
    "\n",
    "cnbc_standard = cnbc_clean[['date', 'Headlines', 'Description']].copy()\n",
    "cnbc_standard.columns = ['date', 'headline', 'description']\n",
    "cnbc_standard['source'] = 'CNBC'\n",
    "\n",
    "cnbc_standard = cnbc_standard.dropna(subset=['date'])\n",
    "\n",
    "print(f'CNBC standardized shape: {cnbc_standard.shape}')\n",
    "print(f'\\nColumns: {list(cnbc_standard.columns)}')\n",
    "print('\\nSample:')\n",
    "print(cnbc_standard.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8zQ4sGy1jJwq",
   "metadata": {
    "id": "8zQ4sGy1jJwq"
   },
   "source": [
    "### 2.2 Guardian Data Processing\n",
    "\n",
    "**Input Schema**: `Time`, `Headlines` (Note: Reversed order, no Description)\n",
    "\n",
    "**Data Irregularities**:\n",
    "- Missing `description` column entirely\n",
    "- Dirty text: `\\n\\n` patterns in headlines\n",
    "- Date format: `18-Jul-20` (Day-Month-Year)\n",
    "\n",
    "**Action Plan**:\n",
    "1. Load CSV\n",
    "2. Clean newlines from Headlines\n",
    "3. Parse DMY date format\n",
    "4. Create empty `description` column (use `\"\"`, not NaN)\n",
    "5. Rename and add source tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "D6_oIUjFjm5z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 561,
     "status": "ok",
     "timestamp": 1770952282769,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "D6_oIUjFjm5z",
    "outputId": "57f5bf7a-771a-4972-e0a6-232b971c10d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Guardian data from /content/drive/MyDrive/market-sentiment-impact-analysis/data/raw/guardian_headlines.csv\n",
      "Initial shape: (17800, 2)\n",
      "First 10 rows:\n",
      "        Time                                          Headlines\n",
      "0  18-Jul-20   Johnson is asking Santa for a Christmas recovery\n",
      "1  18-Jul-20  ‘I now fear the worst’: four grim tales of wor...\n",
      "2  18-Jul-20  Five key areas Sunak must tackle to serve up e...\n",
      "3  18-Jul-20  Covid-19 leaves firms ‘fatally ill-prepared’ f...\n",
      "4  18-Jul-20  The Week in Patriarchy  \\n\\n\\n  Bacardi's 'lad...\n",
      "5  18-Jul-20  English councils call for smoking ban outside ...\n",
      "6  18-Jul-20              Can Tesla justify a $300bn valuation?\n",
      "7  18-Jul-20  Empty city centres: 'I’m not sure it will ever...\n",
      "8  18-Jul-20  Democratising finance for all? An investment a...\n",
      "9  18-Jul-20  Homebuyer loses £300,000 to fraudsters – but g...\n",
      "Column names: ['Time', 'Headlines']\n"
     ]
    }
   ],
   "source": [
    "guardian_path = os.path.join(data_raw, 'guardian_headlines.csv')\n",
    "\n",
    "print(f'Loading Guardian data from {guardian_path}')\n",
    "guardian_raw = pd.read_csv(guardian_path)\n",
    "\n",
    "print(f'Initial shape: {guardian_raw.shape}')\n",
    "print(f'First 10 rows:')\n",
    "print(guardian_raw.head(10))\n",
    "print(f'Column names: {list(guardian_raw.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "XZiXwZJMkL8V",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1770952282776,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "XZiXwZJMkL8V",
    "outputId": "cec3c499-c749-4637-e493-3722f214040f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headlines with newlines: 1246\n",
      "\n",
      "Before/After sample:\n",
      "BEFORE: \"The Week in Patriarchy  \\n\\n\\n  Bacardi's 'lady vodka': the latest in a long line of depressing gendered products\"\n",
      "AFTER:  The Week in Patriarchy Bacardi's 'lady vodka': the latest in a long line of depressing gendered products\n"
     ]
    }
   ],
   "source": [
    "# Clean newlines from Headlines\n",
    "\n",
    "def clean_newlines(text):\n",
    "    \"\"\"Replace multiple newlines and tabs with single space.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "\n",
    "    cleaned = str(text).replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ')\n",
    "    cleaned = ' '.join(cleaned.split())\n",
    "    return cleaned\n",
    "\n",
    "guardian_raw['Headlines_Cleaned'] = guardian_raw['Headlines'].apply(clean_newlines)\n",
    "\n",
    "has_newlines = guardian_raw['Headlines'].str.contains('\\n', na=False)\n",
    "print(f'Headlines with newlines: {has_newlines.sum()}')\n",
    "print(f'\\nBefore/After sample:')\n",
    "if has_newlines.sum() > 0:\n",
    "    sample_idx = guardian_raw[has_newlines].index[0]\n",
    "    print(f'BEFORE: {repr(guardian_raw.loc[sample_idx, 'Headlines'])}')\n",
    "    print(f'AFTER:  {guardian_raw.loc[sample_idx, 'Headlines_Cleaned']}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "zveanwSUlrLt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2241,
     "status": "ok",
     "timestamp": 1770952285018,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "zveanwSUlrLt",
    "outputId": "bb3ad2b8-5189-432f-d867-efc0f5ef7b1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date parsing results:\n",
      "Successfully parsed: 17760\n",
      "Failed to parse: 40\n",
      "\n",
      "Date range:\n",
      "Earliest: 2017-12-17 00:00:00\n",
      "Latest: 2020-07-18 00:00:00\n"
     ]
    }
   ],
   "source": [
    "from pandas.core.dtypes.missing import isna\n",
    "# Parse date - format is \"18-Jul-20\" (DMY)\n",
    "\n",
    "def parse_guardian_date(date_str):\n",
    "    if pd.isna(date_str):\n",
    "        return pd.NaT\n",
    "    try:\n",
    "        return pd.to_datetime(date_str, format='%d-%b-%y')\n",
    "    except:\n",
    "        return pd.NaT\n",
    "\n",
    "guardian_raw['date'] = guardian_raw['Time'].apply(parse_guardian_date)\n",
    "\n",
    "print('Date parsing results:')\n",
    "print(f'Successfully parsed: {guardian_raw['date'].notna().sum()}')\n",
    "print(f'Failed to parse: {guardian_raw['date'].isna().sum()}')\n",
    "print('\\nDate range:')\n",
    "print(f'Earliest: {guardian_raw['date'].min()}')\n",
    "print(f'Latest: {guardian_raw['date'].max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "X3o2CWwOmmWa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1770952285022,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "X3o2CWwOmmWa",
    "outputId": "eff91b07-e5a7-4a02-c902-1da07f9ff05d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardian standardized shape: (17760, 4)\n",
      "\n",
      "Columns: ['date', 'headline', 'description', 'source']\n",
      "\n",
      "Description column check:\n",
      "  Type: <class 'str'>\n",
      "  Is NaN: 0\n",
      "  Is empty string: 17760\n",
      "\n",
      "Sample:\n",
      "        date                                           headline description    source\n",
      "0 2020-07-18   Johnson is asking Santa for a Christmas recovery              Guardian\n",
      "1 2020-07-18  ‘I now fear the worst’: four grim tales of wor...              Guardian\n",
      "2 2020-07-18  Five key areas Sunak must tackle to serve up e...              Guardian\n"
     ]
    }
   ],
   "source": [
    "# Schema standardization\n",
    "\n",
    "guardian_standard = pd.DataFrame({\n",
    "    'date': guardian_raw['date'],\n",
    "    'headline': guardian_raw['Headlines_Cleaned'],\n",
    "    'description': '',\n",
    "    'source': 'Guardian'\n",
    "})\n",
    "\n",
    "guardian_standard = guardian_standard.dropna(subset=['date'])\n",
    "\n",
    "print(f'Guardian standardized shape: {guardian_standard.shape}')\n",
    "print(f'\\nColumns: {list(guardian_standard.columns)}')\n",
    "print('\\nDescription column check:')\n",
    "print(f'  Type: {type(guardian_standard['description'].iloc[0])}')\n",
    "print(f'  Is NaN: {guardian_standard['description'].isna().sum()}')\n",
    "print(f'  Is empty string: {(guardian_standard['description'] == '').sum()}')\n",
    "print('\\nSample:')\n",
    "print(guardian_standard.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2j_vg_SEn8PE",
   "metadata": {
    "id": "2j_vg_SEn8PE"
   },
   "source": [
    "### 2.3 Reuters Data Processing\n",
    "\n",
    "**Input Schema**: `Headlines`, `Time`, `Description`\n",
    "\n",
    "**Data Irregularities**: Minimal - clean format `\"Jul 18 2020\"`\n",
    "\n",
    "**Action Plan**:\n",
    "1. Load CSV\n",
    "2. Parse clean date format (MMM DD YYYY)\n",
    "3. Rename columns to standard schema\n",
    "4. Add source tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9Ys2LuLjoIQE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 835,
     "status": "ok",
     "timestamp": 1770952285858,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "9Ys2LuLjoIQE",
    "outputId": "41e45e37-df9c-4332-ad11-235e888fea96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Reuters data from: /content/drive/MyDrive/market-sentiment-impact-analysis/data/raw/reuters_headlines.csv\n",
      "Initial shape: (32770, 3)\n",
      "\n",
      "First 5 rows:\n",
      "                                           Headlines         Time                                        Description\n",
      "0  TikTok considers London and other locations fo...  Jul 18 2020  TikTok has been in discussions with the UK gov...\n",
      "1  Disney cuts ad spending on Facebook amid growi...  Jul 18 2020  Walt Disney  has become the latest company to ...\n",
      "2  Trail of missing Wirecard executive leads to B...  Jul 18 2020  Former Wirecard  chief operating officer Jan M...\n",
      "3  Twitter says attackers downloaded data from up...  Jul 18 2020  Twitter Inc said on Saturday that hackers were...\n",
      "4  U.S. Republicans seek liability protections as...  Jul 17 2020  A battle in the U.S. Congress over a new coron...\n",
      "\n",
      "Column names: ['Headlines', 'Time', 'Description']\n"
     ]
    }
   ],
   "source": [
    "reuters_path = os.path.join(data_raw, 'reuters_headlines.csv')\n",
    "\n",
    "print(f'Loading Reuters data from: {reuters_path}')\n",
    "reuters_raw = pd.read_csv(reuters_path)\n",
    "\n",
    "print(f'Initial shape: {reuters_raw.shape}')\n",
    "print('\\nFirst 5 rows:')\n",
    "print(reuters_raw.head())\n",
    "print(f'\\nColumn names: {list(reuters_raw.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "K5gBcnxZoqCQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5625,
     "status": "ok",
     "timestamp": 1770952291485,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "K5gBcnxZoqCQ",
    "outputId": "a3b68367-7593-4f66-96b3-c65a58919176"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date parsing results:\n",
      "Successfully parsed: 32770\n",
      "Failed to parse: 0\n",
      "\n",
      "Date range:\n",
      "Earliest: 2018-03-20 00:00:00\n",
      "Latest: 2020-07-18 00:00:00\n",
      "\n",
      "Sample parsed dates:\n",
      "          Time       date\n",
      "0  Jul 18 2020 2020-07-18\n",
      "1  Jul 18 2020 2020-07-18\n",
      "2  Jul 18 2020 2020-07-18\n",
      "3  Jul 18 2020 2020-07-18\n",
      "4  Jul 17 2020 2020-07-17\n"
     ]
    }
   ],
   "source": [
    "# Parse date, format is \"Jul 18 2020\" (MMM DD YYYY)\n",
    "\n",
    "def parse_reuters_date(date_str):\n",
    "    if pd.isna(date_str):\n",
    "        return pd.NaT\n",
    "    try:\n",
    "        return pd.to_datetime(date_str, format='%b %d %Y')\n",
    "    except:\n",
    "        return pd.NaT\n",
    "\n",
    "reuters_raw['date'] = reuters_raw['Time'].apply(parse_reuters_date)\n",
    "\n",
    "print('Date parsing results:')\n",
    "print(f'Successfully parsed: {reuters_raw['date'].notna().sum()}')\n",
    "print(f'Failed to parse: {reuters_raw['date'].isna().sum()}')\n",
    "print('\\nDate range:')\n",
    "print(f'Earliest: {reuters_raw['date'].min()}')\n",
    "print(f'Latest: {reuters_raw['date'].max()}')\n",
    "print('\\nSample parsed dates:')\n",
    "print(reuters_raw[['Time', 'date']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "nz4K87bnpr-V",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1770952291493,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "nz4K87bnpr-V",
    "outputId": "d6556014-1077-401b-8ae5-6dbf472a9345"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reuters standardized shape: (32770, 4)\n",
      "Columns: ['date', 'headline', 'description', 'source']\n",
      "\n",
      "Sample:\n",
      "        date                                           headline                                        description   source\n",
      "0 2020-07-18  TikTok considers London and other locations fo...  TikTok has been in discussions with the UK gov...  Reuters\n",
      "1 2020-07-18  Disney cuts ad spending on Facebook amid growi...  Walt Disney  has become the latest company to ...  Reuters\n",
      "2 2020-07-18  Trail of missing Wirecard executive leads to B...  Former Wirecard  chief operating officer Jan M...  Reuters\n"
     ]
    }
   ],
   "source": [
    "# Schema standardization\n",
    "\n",
    "reuters_standard = pd.DataFrame({\n",
    "    'date': reuters_raw['date'],\n",
    "    'headline': reuters_raw['Headlines'],\n",
    "    'description': reuters_raw['Description'],\n",
    "    'source': 'Reuters'\n",
    "})\n",
    "\n",
    "reuters_standard = reuters_standard.dropna(subset=['date'])\n",
    "\n",
    "print(f'Reuters standardized shape: {reuters_standard.shape}')\n",
    "print(f'Columns: {list(reuters_standard.columns)}')\n",
    "print('\\nSample:')\n",
    "print(reuters_standard.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9Ra5IEKIhCBR",
   "metadata": {
    "id": "9Ra5IEKIhCBR"
   },
   "source": [
    "---\n",
    "\n",
    "## 3. Global News Standardization\n",
    "\n",
    "Now that all sources have identical schemas (`date`, `headline`, `description`, `source`), we merge and refine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sGHcYodhhccv",
   "metadata": {
    "id": "sGHcYodhhccv"
   },
   "source": [
    "### 3.1 Concatenation & Time Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "G4QrojjYhQ2v",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1770952291501,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "G4QrojjYhQ2v",
    "outputId": "dae63c3f-31ee-451f-f896-146d6df9c830"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined news shape: (53330, 4)\n",
      "\n",
      "Records per source:\n",
      "source\n",
      "Reuters     32770\n",
      "Guardian    17760\n",
      "CNBC         2800\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Date range before filtering:\n",
      "  Earliest: 2017-12-17 00:00:00\n",
      "  Latest: 2020-07-18 00:00:00\n"
     ]
    }
   ],
   "source": [
    "from numpy._core.defchararray import index\n",
    "# Combine all three news sources\n",
    "\n",
    "news_sources = [cnbc_standard, guardian_standard, reuters_standard]\n",
    "\n",
    "news_combined = pd.concat(news_sources, ignore_index=True)\n",
    "\n",
    "print(f'Combined news shape: {news_combined.shape}')\n",
    "print('\\nRecords per source:')\n",
    "print(news_combined['source'].value_counts())\n",
    "print('\\nDate range before filtering:')\n",
    "print(f'  Earliest: {news_combined['date'].min()}')\n",
    "print(f'  Latest: {news_combined['date'].max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "GzockcsqiIhk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1770952291507,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "GzockcsqiIhk",
    "outputId": "af7a3c5e-ef26-4bf1-f6bc-9396532bbc5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying hard cut filter:\n",
      "  Start: 2018-01-01\n",
      "  End: 2020-07-19\n",
      "\n",
      "Rows removed (outside date range): 245\n",
      "Rows retained: 53085\n",
      "\n",
      "Final date range:\n",
      "  Earliest: 2018-01-02\n",
      "  Latest: 2020-07-18\n"
     ]
    }
   ],
   "source": [
    "# Target range: 2018-01-01 to 2020-07-19\n",
    "\n",
    "news_combined['date'] = pd.to_datetime(news_combined['date'], utc=True)\n",
    "\n",
    "start_date = pd.Timestamp('2018-01-01', tz='UTC')\n",
    "end_date = pd.Timestamp('2020-07-19', tz='UTC')\n",
    "\n",
    "print('Applying hard cut filter:')\n",
    "print(f'  Start: {start_date.date()}')\n",
    "print(f'  End: {end_date.date()}')\n",
    "\n",
    "news_filtered = news_combined[\n",
    "    (news_combined['date'] >= start_date) &\n",
    "    (news_combined['date'] <= end_date)\n",
    "].copy()\n",
    "\n",
    "news_filtered = news_filtered.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "rows_removed = len(news_combined) - len(news_filtered)\n",
    "print(f'\\nRows removed (outside date range): {rows_removed}')\n",
    "print(f'Rows retained: {len(news_filtered)}')\n",
    "print('\\nFinal date range:')\n",
    "print(f'  Earliest: {news_filtered['date'].min().date()}')\n",
    "print(f'  Latest: {news_filtered['date'].max().date()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dqDFWaGnjdYC",
   "metadata": {
    "id": "dqDFWaGnjdYC"
   },
   "source": [
    "### 3.2 Text Engineering: Creating the \"Context\" Field\n",
    "\n",
    "**Problem**: Headlines alone are too short for FinBERT b/c transformers work best with full sentences\n",
    "\n",
    "**Solution**: Concatenate `headline + \". \" + description`\n",
    "\n",
    "**Edge Cases**:\n",
    "- Guardian has empty description → result should be just headline\n",
    "- No trailing \". \" for empty descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ZmEzXF8fjrte",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 612,
     "status": "ok",
     "timestamp": 1770952292120,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "ZmEzXF8fjrte",
    "outputId": "2f76e5be-ae21-4214-d688-7a4b6776ea16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text engineering results:\n",
      "\n",
      "Sample from CNBC (has description):\n",
      "Headline: The major indexes trade lower in January...\n",
      "Description: Our data partners at Kensho say beware of January. Since 2012 on average the Nasdaq, S&P 500, Dow an...\n",
      "Final Text: The major indexes trade lower in January. Our data partners at Kensho say beware of January. Since 2012 on average the Nasdaq, S&P 500, Dow and Russel...\n",
      "\n",
      "Sample from Guardian (no description):\n",
      "Headline: Former advertising executive reveals junk food-pushing tactics...\n",
      "Description: ''\n",
      "Final Text: Former advertising executive reveals junk food-pushing tactics...\n"
     ]
    }
   ],
   "source": [
    "# Create final_text by concatenating headline and description\n",
    "\n",
    "def create_final_text(row):\n",
    "    headline = str(row['headline']) if pd.notna(row['headline']) else ''\n",
    "    description = str(row['description']) if pd.notna(row['description']) else ''\n",
    "\n",
    "    if description.strip() == '':\n",
    "        return headline.strip()\n",
    "    else:\n",
    "        return f\"{headline.strip()}. {description.strip()}\"\n",
    "\n",
    "news_filtered['final_text'] = news_filtered.apply(create_final_text, axis=1)\n",
    "print('Text engineering results:')\n",
    "print(f'\\nSample from CNBC (has description):')\n",
    "cnbc_sample = news_filtered[news_filtered['source'] == 'CNBC'].iloc[0]\n",
    "print(f'Headline: {cnbc_sample['headline'][:100]}...')\n",
    "print(f'Description: {cnbc_sample['description'][:100]}...')\n",
    "print(f'Final Text: {cnbc_sample['final_text'][:150]}...')\n",
    "\n",
    "print('\\nSample from Guardian (no description):')\n",
    "guardian_sample = news_filtered[news_filtered['source'] == 'Guardian'].iloc[0]\n",
    "print(f'Headline: {guardian_sample['headline'][:100]}...')\n",
    "print(f\"Description: '{guardian_sample['description']}'\")\n",
    "print(f'Final Text: {guardian_sample['final_text'][:150]}...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9iidyGRk_ZQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 117,
     "status": "ok",
     "timestamp": 1770952292239,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "d9iidyGRk_ZQ",
    "outputId": "b2590880-ffb6-4283-ef8e-2962a7fe01a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results:\n",
      "  NaN values in final_text: 0\n",
      "  Empty strings in final_text: 0\n",
      "\n",
      "Text length statistics:\n",
      "count    53085.000000\n",
      "mean       206.593444\n",
      "std        105.747685\n",
      "min         18.000000\n",
      "25%         74.000000\n",
      "50%        248.000000\n",
      "75%        295.000000\n",
      "max        566.000000\n",
      "Name: text_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "nan_count = news_filtered['final_text'].isna().sum()\n",
    "empty_count = (news_filtered['final_text'].str.strip() == '').sum()\n",
    "\n",
    "print('Validation Results:')\n",
    "print(f'  NaN values in final_text: {nan_count}')\n",
    "print(f'  Empty strings in final_text: {empty_count}')\n",
    "\n",
    "news_filtered['text_length'] = news_filtered['final_text'].str.len()\n",
    "print(f'\\nText length statistics:')\n",
    "print(news_filtered['text_length'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bus20l6sl94X",
   "metadata": {
    "id": "bus20l6sl94X"
   },
   "source": [
    "### 3.3 Deduplication: Bias Removal\n",
    "\n",
    "**Problem**: Wire services (Reuters/CNBC/Guardian) often syndicate the same story\n",
    "\n",
    "**Impact**: Duplicate stories artificially inflate sentiment on certain dates\n",
    "\n",
    "**Solution**: Drop duplicates based on `final_text`, keeping first occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04MQS2ofmDRl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 99,
     "status": "ok",
     "timestamp": 1770952292333,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "04MQS2ofmDRl",
    "outputId": "1b8700f8-299b-43e0-e653-ad109b5b1e0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplication Analysis:\n",
      "  Total records: 53085\n",
      "  Duplicate texts (all occurrences): 212\n",
      "  Unique texts: 52974\n",
      "\n",
      "Sample duplicate entries:\n",
      "                         date source                                         final_text\n",
      "73  2018-01-04 19:06:00+00:00   CNBC  Cramer Remix: Even at Dow 25K, this market is ...\n",
      "74  2018-01-04 19:21:00+00:00   CNBC  Cramer Remix: Even at Dow 25K, this market is ...\n",
      "102 2018-01-05 17:18:00+00:00   CNBC  Cramer: The S&P 500's winners for 2017 could s...\n",
      "103 2018-01-05 18:54:00+00:00   CNBC  Cramer says the S&P 500's biggest 2017 losers ...\n"
     ]
    }
   ],
   "source": [
    "total_before = len(news_filtered)\n",
    "duplicates = news_filtered['final_text'].duplicated(keep=False).sum()\n",
    "\n",
    "print('Duplication Analysis:')\n",
    "print(f'  Total records: {total_before}')\n",
    "print(f'  Duplicate texts (all occurrences): {duplicates}')\n",
    "print(f'  Unique texts: {news_filtered['final_text'].nunique()}')\n",
    "\n",
    "if duplicates > 0:\n",
    "    dup_example = news_filtered[news_filtered['final_text'].duplicated(keep=False)].head(4)\n",
    "    print(f'\\nSample duplicate entries:')\n",
    "    print(dup_example[['date', 'source', 'final_text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "MZXySXHrmnNR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1770952292358,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "MZXySXHrmnNR",
    "outputId": "93b06c3e-686d-4f79-eee7-b4de1d194281"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deduplication Results:\n",
      "  Before: 53,085 records\n",
      "  After: 52,974 records\n",
      "  Removed: 111 duplicates (0.21%)\n"
     ]
    }
   ],
   "source": [
    "news_deduped = news_filtered.drop_duplicates(subset=['final_text'], keep='first')\n",
    "\n",
    "total_after = len(news_deduped)\n",
    "removed = total_before - total_after\n",
    "removal_pct = (removed / total_before) * 100\n",
    "\n",
    "print('\\nDeduplication Results:')\n",
    "print(f'  Before: {total_before:,} records')\n",
    "print(f'  After: {total_after:,} records')\n",
    "print(f'  Removed: {removed:,} duplicates ({removal_pct:.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IZb45ot6m3kK",
   "metadata": {
    "id": "IZb45ot6m3kK"
   },
   "source": [
    "### 3.4 Final News Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "Xx2LMFNsm55m",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1770952292361,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "Xx2LMFNsm55m",
    "outputId": "cb029e7c-3674-46f5-af80-0a08da341494"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final news dataset:\n",
      "  Shape: (52974, 3)\n",
      "  Columns: ['date', 'source', 'final_text']\n",
      "  Date range: 2018-01-02 to 2020-07-18\n",
      "  Records per source:\n",
      "source\n",
      "Reuters     32673\n",
      "Guardian    17516\n",
      "CNBC         2785\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First 3 records:\n",
      "                       date    source                                         final_text\n",
      "0 2018-01-02 00:00:00+00:00  Guardian  Former advertising executive reveals junk food...\n",
      "1 2018-01-02 00:00:00+00:00  Guardian  Transport secretary ‘running scared’ as he fli...\n",
      "2 2018-01-02 00:00:00+00:00  Guardian  Good for factories, bad for shoppers: a Brexit...\n"
     ]
    }
   ],
   "source": [
    "# Select final columns for output\n",
    "# Keep: date, source, final_text\n",
    "\n",
    "news_final = news_deduped[['date', 'source', 'final_text']].copy()\n",
    "news_final = news_final.reset_index(drop=True)\n",
    "\n",
    "print('Final news dataset:')\n",
    "print(f'  Shape: {news_final.shape}')\n",
    "print(f'  Columns: {list(news_final.columns)}')\n",
    "print(f'  Date range: {news_final['date'].min().date()} to {news_final['date'].max().date()}')\n",
    "print('  Records per source:')\n",
    "print(news_final['source'].value_counts())\n",
    "print('\\nFirst 3 records:')\n",
    "print(news_final.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aCpKCd8c-Lr",
   "metadata": {
    "id": "2aCpKCd8c-Lr"
   },
   "source": [
    "---\n",
    "\n",
    "## 4. Stock Data Integration\n",
    "\n",
    "Preparing the target variables for statistical analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2tNXKd56dcPL",
   "metadata": {
    "id": "2tNXKd56dcPL"
   },
   "source": [
    "### 4.1 Ticker Aggregation & Metadata Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fv56e9jhdmI_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 523,
     "status": "ok",
     "timestamp": 1770952292884,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "fv56e9jhdmI_",
    "outputId": "04c871e2-3ef2-49aa-b1b5-b20e36aadaf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "High Beta stocks: 30\n",
      "  Ticker                        Security             GICS Sector      Beta\n",
      "0    APA                 APA Corporation                  Energy  1.950480\n",
      "1   NCLH  Norwegian Cruise Line Holdings  Consumer Discretionary  1.936777\n",
      "2   CVNA                         Carvana  Consumer Discretionary  1.919910\n",
      "3    CCL                        Carnival  Consumer Discretionary  1.837347\n",
      "4   TRGP                 Targa Resources                  Energy  1.830136\n",
      "\n",
      "Low Beta stocks: 30\n",
      "  Ticker                    Security       GICS Sector      Beta\n",
      "0    NEM                     Newmont         Materials  0.290109\n",
      "1    CLX                      Clorox  Consumer Staples  0.330349\n",
      "2     KR                      Kroger  Consumer Staples  0.342843\n",
      "3    CPB    Campbell's Company (The)  Consumer Staples  0.345294\n",
      "4    SJM  J.M. Smucker Company (The)  Consumer Staples  0.385139\n"
     ]
    }
   ],
   "source": [
    "high_beta_path = os.path.join(data_tickers, 'high_beta.csv')\n",
    "low_beta_path = os.path.join(data_tickers, 'low_beta.csv')\n",
    "\n",
    "high_beta_df = pd.read_csv(high_beta_path)\n",
    "low_beta_df = pd.read_csv(low_beta_path)\n",
    "\n",
    "print(f'\\nHigh Beta stocks: {len(high_beta_df)}')\n",
    "print(high_beta_df[['Ticker', 'Security', 'GICS Sector', 'Beta']].head())\n",
    "\n",
    "print(f\"\\nLow Beta stocks: {len(low_beta_df)}\")\n",
    "print(low_beta_df[['Ticker', 'Security', 'GICS Sector', 'Beta']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "vrWb9ZrieMtm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1770952292991,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "vrWb9ZrieMtm",
    "outputId": "854384f5-e319-480f-e6a1-f9c142f82ca9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total tickers: 60\n",
      "High Beta: 30\n",
      "Low Beta: 30\n",
      "\n",
      "Ticker list: ['APA', 'NCLH', 'CVNA', 'CCL', 'TRGP', 'RCL', 'MGM', 'HAL', 'AMP', 'OXY', 'XYZ', 'DVN', 'ON', 'TPR', 'BA', 'FCX', 'URI', 'MPC', 'WDC', 'PRU', 'LRCX', 'SYF', 'WYNN', 'OKE', 'KEY', 'C', 'IVZ', 'COF', 'FANG', 'TTD', 'NEM', 'CLX', 'KR', 'CPB', 'SJM', 'GIS', 'HRL', 'SW', 'CAG', 'CHD', 'VZ', 'DPZ', 'WMT', 'KDP', 'ED', 'KMB', 'DG', 'AEP', 'CHRW', 'PSA', 'EXR', 'WEC', 'GILD', 'CMS', 'CL', 'GEN', 'MKC', 'COST', 'PG', 'LNT']\n"
     ]
    }
   ],
   "source": [
    "high_beta_df['Beta_Group'] = 'High Beta'\n",
    "low_beta_df['Beta_Group'] = 'Low Beta'\n",
    "\n",
    "ticker_metadata = pd.concat([high_beta_df, low_beta_df], ignore_index=True)\n",
    "\n",
    "all_tickers = ticker_metadata['Ticker'].tolist()\n",
    "\n",
    "print(f'\\nTotal tickers: {len(all_tickers)}')\n",
    "print(f'High Beta: {len(high_beta_df)}')\n",
    "print(f'Low Beta: {len(low_beta_df)}')\n",
    "print(f'\\nTicker list: {all_tickers}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "k3ot6s_Jex_c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1770952292996,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "k3ot6s_Jex_c",
    "outputId": "3c03d87a-6500-491d-9d3a-bb3be90132a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample ticker mapping:\n",
      "APA: {'GICS Sector': 'Energy', 'Beta': 1.9504802306078584, 'Beta_Group': 'High Beta'}\n"
     ]
    }
   ],
   "source": [
    "ticker_map = ticker_metadata.set_index('Ticker')[['GICS Sector', 'Beta', 'Beta_Group']].to_dict('index')\n",
    "\n",
    "print('\\nSample ticker mapping:')\n",
    "sample_ticker = all_tickers[0]\n",
    "print(f'{sample_ticker}: {ticker_map[sample_ticker]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m5QmdSqXfixF",
   "metadata": {
    "id": "m5QmdSqXfixF"
   },
   "source": [
    "### 4.2 Batch Price Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "iKbbWtLff0jF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10143,
     "status": "ok",
     "timestamp": 1770952303140,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "iKbbWtLff0jF",
    "outputId": "b1373b02-9046-4c78-e575-65b5a06c9458"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading stock data...\n",
      "  Tickers: 60\n",
      "  Date range: 2018-01-01 to 2020-07-19\n",
      "  Interval: Daily\n",
      "Shape: (640, 60) (rows=trading days, columns=stocks)\n",
      "Date range: 2018-01-02 00:00:00 to 2020-07-17 00:00:00\n",
      "Trading days: 640\n"
     ]
    }
   ],
   "source": [
    "# Download historical prices for all 60 tickers: 2018-01-01 to 2020-07-19\n",
    "\n",
    "end_date = '2020-07-19'\n",
    "start_date = '2018-01-01'\n",
    "\n",
    "print('\\nDownloading stock data...')\n",
    "print(f'  Tickers: {len(all_tickers)}')\n",
    "print(f'  Date range: {start_date} to {end_date}')\n",
    "print(f'  Interval: Daily')\n",
    "\n",
    "prices_raw = yf.download(\n",
    "    all_tickers,\n",
    "    start=start_date,\n",
    "    end=end_date,\n",
    "    interval='1d',\n",
    "    auto_adjust=True,\n",
    "    progress=False\n",
    ")['Close']\n",
    "\n",
    "print(f'Shape: {prices_raw.shape} (rows=trading days, columns=stocks)')\n",
    "print(f'Date range: {prices_raw.index[0]} to {prices_raw.index[-1]}')\n",
    "print(f'Trading days: {len(prices_raw)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8z7JF4NBgvUB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1770952303152,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "8z7JF4NBgvUB",
    "outputId": "bb3f4121-a917-4774-f45d-7b81a34b38bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stocks with missing data: 0\n",
      "No missing data detected\n"
     ]
    }
   ],
   "source": [
    "missing_data = prices_raw.isna().sum()\n",
    "stocks_with_missing = missing_data[missing_data > 0].sort_values(ascending=False)\n",
    "\n",
    "print(f'Stocks with missing data: {len(stocks_with_missing)}')\n",
    "\n",
    "if len(stocks_with_missing) > 0:\n",
    "    print(f'\\nStocks with most missing data:')\n",
    "    print(stocks_with_missing.head(10))\n",
    "\n",
    "    pct_missing = (stocks_with_missing / len(prices_raw) * 100)\n",
    "    print(f'\\nPercentage missing:')\n",
    "    print(pct_missing.head(10).round(2))\n",
    "else:\n",
    "    print('No missing data detected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "oVRHpDgkiYO6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1770952303187,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "oVRHpDgkiYO6",
    "outputId": "f5bdd93f-c41d-42fc-e41c-8638e0feeca5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning:\n",
      "  Original days: 640\n",
      "  Clean days: 640\n",
      "  Days removed: 0\n",
      "Price data ready for return calculation\n"
     ]
    }
   ],
   "source": [
    "prices_filled = prices_raw.fillna(method='ffill')\n",
    "prices_clean = prices_filled.dropna(axis=0, how='any')\n",
    "\n",
    "print('After cleaning:')\n",
    "print(f'  Original days: {len(prices_raw)}')\n",
    "print(f'  Clean days: {len(prices_clean)}')\n",
    "print(f'  Days removed: {len(prices_raw) - len(prices_clean)}')\n",
    "print('Price data ready for return calculation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bYZRWu3oi47F",
   "metadata": {
    "id": "bYZRWu3oi47F"
   },
   "source": [
    "### 4.3 Feature Engineering: Log Returns\n",
    "\n",
    "**Mathematical Foundation**:\n",
    "\n",
    "$$R_t = \\ln\\left(\\frac{P_t}{P_{t-1}}\\right) = \\ln(P_t) - \\ln(P_{t-1})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "NxhMPJZDjE7v",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1770952303204,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "NxhMPJZDjE7v",
    "outputId": "2de25032-662e-4e0a-cb99-25bec7ce363c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returns calculated:\n",
      "  Shape: (639, 60)\n",
      "  Date range: 2018-01-03 00:00:00 to 2020-07-17 00:00:00\n",
      "\n",
      "Sample returns (first stock, first 5 days):\n",
      "Date\n",
      "2018-01-03   -0.008460\n",
      "2018-01-04   -0.011909\n",
      "2018-01-05   -0.002116\n",
      "2018-01-08    0.008719\n",
      "2018-01-09   -0.011831\n",
      "Name: AEP, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "returns = np.log(prices_clean / prices_clean.shift(1))\n",
    "returns = returns.dropna()\n",
    "\n",
    "print('Returns calculated:')\n",
    "print(f'  Shape: {returns.shape}')\n",
    "print(f'  Date range: {returns.index[0]} to {returns.index[-1]}')\n",
    "print('\\nSample returns (first stock, first 5 days):')\n",
    "print(returns.iloc[:5, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "rFaaou0Wjik_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1770952303207,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "rFaaou0Wjik_",
    "outputId": "ce11302d-da73-467b-ee6d-8163f87158f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return quality checks:\n",
      "  Extreme returns (|R| > 30%): 31\n",
      "  Infinite values: 0\n"
     ]
    }
   ],
   "source": [
    "extreme_returns = (returns.abs() > 0.3).sum().sum()\n",
    "infinite_returns = np.isinf(returns).sum().sum()\n",
    "\n",
    "print('Return quality checks:')\n",
    "print(f'  Extreme returns (|R| > 30%): {extreme_returns}')\n",
    "print(f'  Infinite values: {infinite_returns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "OLa5NuRJj-n0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1770952303241,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "OLa5NuRJj-n0",
    "outputId": "8690db60-d37c-4f26-b0c1-4309bc183c73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Return Statistics (across all stocks):\n",
      "  Mean: -0.000087\n",
      "  Median: 0.000899\n",
      "  Std Dev: 0.028545\n",
      "  Min: -0.773592\n",
      "  Max: 0.360404\n",
      "\n",
      "Annualized Volatility (mean): 0.453\n",
      "  High Beta stocks: 0.616\n",
      "  Low Beta stocks: 0.291\n"
     ]
    }
   ],
   "source": [
    "print('\\nReturn Statistics (across all stocks):')\n",
    "print(f'  Mean: {returns.mean().mean():.6f}')\n",
    "print(f'  Median: {returns.median().median():.6f}')\n",
    "print(f'  Std Dev: {returns.std().mean():.6f}')\n",
    "print(f'  Min: {returns.min().min():.6f}')\n",
    "print(f'  Max: {returns.max().max():.6f}')\n",
    "\n",
    "annualized_vol = returns.std() * np.sqrt(252)\n",
    "print(f'\\nAnnualized Volatility (mean): {annualized_vol.mean():.3f}')\n",
    "print(f'  High Beta stocks: {annualized_vol[high_beta_df['Ticker']].mean():.3f}')\n",
    "print(f'  Low Beta stocks: {annualized_vol[low_beta_df['Ticker']].mean():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EG2RrqHmkXsR",
   "metadata": {
    "id": "EG2RrqHmkXsR"
   },
   "source": [
    "### 4.4 Reshape to Long Format & Enrich with Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ocw32vCkl6E",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1770952303262,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "8ocw32vCkl6E",
    "outputId": "b09635ac-9816-48e4-d190-0a9b05bb98e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped to long format:\n",
      "  Shape: (38340, 3)\n",
      "  Columns: ['Date', 'Ticker', 'Log_Return']\n",
      "\n",
      "Sample:\n",
      "        Date Ticker  Log_Return\n",
      "0 2018-01-03    AEP   -0.008460\n",
      "1 2018-01-04    AEP   -0.011909\n",
      "2 2018-01-05    AEP   -0.002116\n",
      "3 2018-01-08    AEP    0.008719\n",
      "4 2018-01-09    AEP   -0.011831\n",
      "5 2018-01-10    AEP   -0.015420\n",
      "6 2018-01-11    AEP   -0.011141\n",
      "7 2018-01-12    AEP   -0.018651\n",
      "8 2018-01-16    AEP    0.000593\n",
      "9 2018-01-17    AEP    0.011050\n"
     ]
    }
   ],
   "source": [
    "# Convert wide format (date × ticker) to long format (date-ticker pairs)\n",
    "\n",
    "returns_long = returns.reset_index()\n",
    "\n",
    "returns_long = returns_long.melt(\n",
    "    id_vars='Date',\n",
    "    var_name='Ticker',\n",
    "    value_name='Log_Return'\n",
    ")\n",
    "\n",
    "print('Reshaped to long format:')\n",
    "print(f'  Shape: {returns_long.shape}')\n",
    "print(f'  Columns: {list(returns_long.columns)}')\n",
    "print('\\nSample:')\n",
    "print(returns_long.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "TroZw_lKk4l-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7294,
     "status": "ok",
     "timestamp": 1770952310555,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "TroZw_lKk4l-",
    "outputId": "a3979274-df10-4713-ef0a-8b5185ba65a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enriched with metadata:\n",
      "  Shape: (38340, 6)\n",
      "  Columns: ['Date', 'Ticker', 'Log_Return', 'Sector', 'Beta', 'Beta_Group']\n",
      "\n",
      "Sample with metadata:\n",
      "        Date Ticker  Log_Return     Sector      Beta Beta_Group\n",
      "0 2018-01-03    AEP   -0.008460  Utilities  0.585551   Low Beta\n",
      "1 2018-01-04    AEP   -0.011909  Utilities  0.585551   Low Beta\n",
      "2 2018-01-05    AEP   -0.002116  Utilities  0.585551   Low Beta\n",
      "3 2018-01-08    AEP    0.008719  Utilities  0.585551   Low Beta\n",
      "4 2018-01-09    AEP   -0.011831  Utilities  0.585551   Low Beta\n"
     ]
    }
   ],
   "source": [
    "def add_metadata(row):\n",
    "    ticker = row['Ticker']\n",
    "    if ticker in ticker_map:\n",
    "        return pd.Series({\n",
    "            'Sector': ticker_map[ticker]['GICS Sector'],\n",
    "            'Beta': ticker_map[ticker]['Beta'],\n",
    "            'Beta_Group': ticker_map[ticker]['Beta_Group']\n",
    "        })\n",
    "    else:\n",
    "        return pd.Series({\n",
    "            'Sector': None,\n",
    "            'Beta': None,\n",
    "            'Beta_Group': None\n",
    "        })\n",
    "\n",
    "metadata_cols = returns_long['Ticker'].apply(lambda t: pd.Series(ticker_map.get(t, {})))\n",
    "returns_enriched = pd.concat([returns_long, metadata_cols], axis=1)\n",
    "\n",
    "if 'GICS Sector' in returns_enriched.columns:\n",
    "    returns_enriched.rename(columns={'GICS Sector': 'Sector'}, inplace=True)\n",
    "\n",
    "print(f'\\nEnriched with metadata:')\n",
    "print(f'  Shape: {returns_enriched.shape}')\n",
    "print(f'  Columns: {list(returns_enriched.columns)}')\n",
    "print('\\nSample with metadata:')\n",
    "print(returns_enriched.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "su1TXvmVlXaW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1770952310566,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "su1TXvmVlXaW",
    "outputId": "e40babff-65ca-47c7-e29b-ba13cdf73f5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final stock returns dataset:\n",
      "  Shape: (38340, 6)\n",
      "  Date range: 2018-01-03 00:00:00 to 2020-07-17 00:00:00\n",
      "  Unique tickers: 60\n",
      "  Observations per ticker: 639\n",
      "\n",
      "Records by Beta Group:\n",
      "Beta_Group\n",
      "Low Beta     19170\n",
      "High Beta    19170\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "returns_final = returns_enriched[['Date', 'Ticker', 'Log_Return', 'Sector', 'Beta', 'Beta_Group']].copy()\n",
    "returns_final = returns_final.sort_values(['Date', 'Ticker']).reset_index(drop=True)\n",
    "\n",
    "print('Final stock returns dataset:')\n",
    "print(f'  Shape: {returns_final.shape}')\n",
    "print(f'  Date range: {returns_final['Date'].min()} to {returns_final['Date'].max()}')\n",
    "print(f'  Unique tickers: {returns_final['Ticker'].nunique()}')\n",
    "print(f'  Observations per ticker: {len(returns_final) / returns_final['Ticker'].nunique():.0f}')\n",
    "print('\\nRecords by Beta Group:')\n",
    "print(returns_final['Beta_Group'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1zehAPmh_GCn",
   "metadata": {
    "id": "1zehAPmh_GCn"
   },
   "source": [
    "---\n",
    "\n",
    "## 5. Validation & Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_LZR1PDh_OFk",
   "metadata": {
    "id": "_LZR1PDh_OFk"
   },
   "source": [
    "### 5.1 Validation Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "WfNcu9ki_TWS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 80,
     "status": "ok",
     "timestamp": 1770953038921,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "WfNcu9ki_TWS",
    "outputId": "423c1b83-fbdb-4501-86ea-c6b9b9ce5cd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Date Range Check:\n",
      "   Expected: 2018-01-01 to 2020-07-19\n",
      "   Actual: 2018-01-02 to 2020-07-18\n",
      "   Status: Pass\n",
      "\n",
      "2. Text Completeness Check:\n",
      "   NaN values in final_text: 0\n",
      "   Status: Pass\n",
      "\n",
      "3. Empty Text Check:\n",
      "   Empty strings: 0\n",
      "   Status: Pass\n",
      "\n",
      "4. Deduplication Check:\n",
      "   Total records: 52974\n",
      "   Unique texts: 52974\n",
      "   Duplicates remaining: 0\n",
      "   Status: Pass\n",
      "\n",
      "All checks passed\n"
     ]
    }
   ],
   "source": [
    "# News data validation\n",
    "# Date range\n",
    "\n",
    "news_min = news_final['date'].min()\n",
    "news_max = news_final['date'].max()\n",
    "expected_start = pd.Timestamp('2018-01-01', tz='UTC')\n",
    "expected_end = pd.Timestamp('2020-07-19', tz='UTC')\n",
    "\n",
    "date_check = (news_min >= expected_start) and (news_max <= expected_end)\n",
    "print(f'\\n1. Date Range Check:')\n",
    "print(f'   Expected: {expected_start.date()} to {expected_end.date()}')\n",
    "print(f'   Actual: {news_min.date()} to {news_max.date()}')\n",
    "print(f'   Status: {'Pass' if date_check else 'Fail'}')\n",
    "\n",
    "# No NaN in final_text\n",
    "\n",
    "nan_text = news_final['final_text'].isna().sum()\n",
    "print(f'\\n2. Text Completeness Check:')\n",
    "print(f'   NaN values in final_text: {nan_text}')\n",
    "print(f'   Status: {'Pass' if nan_text == 0 else 'Fail'}')\n",
    "\n",
    "# No empty strings\n",
    "\n",
    "empty_text = (news_final['final_text'].str.strip() == '').sum()\n",
    "print(f'\\n3. Empty Text Check:')\n",
    "print(f'   Empty strings: {empty_text}')\n",
    "print(f'   Status: {'Pass' if empty_text == 0 else 'Warning'}')\n",
    "\n",
    "# Unique count (post-deduplication)\n",
    "total_records = len(news_final)\n",
    "unique_texts = news_final['final_text'].nunique()\n",
    "print(f'\\n4. Deduplication Check:')\n",
    "print(f'   Total records: {total_records}')\n",
    "print(f'   Unique texts: {unique_texts}')\n",
    "print(f'   Duplicates remaining: {total_records - unique_texts}')\n",
    "print(f'   Status: {'Pass' if total_records == unique_texts else 'Warning'}')\n",
    "\n",
    "if all([date_check, nan_text == 0, empty_text == 0, total_records == unique_texts]):\n",
    "    print('\\nAll checks passed')\n",
    "else:\n",
    "    print('\\nValidation failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "w0M2zLvJBqV5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1770953655105,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "w0M2zLvJBqV5",
    "outputId": "cd547065-3d80-4957-88b9-20b84b8c42c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Ticker Count Check:\n",
      "   Expected: 60\n",
      "   Actual: 60\n",
      "   Status: Pass\n",
      "\n",
      "2. Infinite Returns Check:\n",
      "   Infinite values: 0\n",
      "   Status: Pass\n",
      "\n",
      "3. NaN Returns Check:\n",
      "   NaN values: 0\n",
      "   Status: Pass\n",
      "\n",
      "4. Metadata Completeness Check:\n",
      "   Missing Sector: 0\n",
      "   Missing Beta: 0\n",
      "   Missing Beta_Group: 0\n",
      "   Status: Pass\n",
      "\n",
      "5. Beta Group Distribution:\n",
      "Beta_Group\n",
      "Low Beta     30\n",
      "High Beta    30\n",
      "Name: count, dtype: int64\n",
      "   Status: Pass\n",
      "\n",
      "All checks passed\n"
     ]
    }
   ],
   "source": [
    "# Stock data validation\n",
    "# Correct number of tickers\n",
    "\n",
    "unique_tickers = returns_final['Ticker'].nunique()\n",
    "expected_tickers = 60\n",
    "ticker_check = (unique_tickers == expected_tickers)\n",
    "print(f'\\n1. Ticker Count Check:')\n",
    "print(f'   Expected: {expected_tickers}')\n",
    "print(f'   Actual: {unique_tickers}')\n",
    "print(f'   Status: {'Pass' if ticker_check else 'Fail'}')\n",
    "\n",
    "# No infinite returns\n",
    "inf_returns = np.isinf(returns_final['Log_Return']).sum()\n",
    "print(f'\\n2. Infinite Returns Check:')\n",
    "print(f'   Infinite values: {inf_returns}')\n",
    "print(f'   Status: {'Pass' if inf_returns == 0 else 'Fail'}')\n",
    "\n",
    "# No NaN returns\n",
    "nan_returns = returns_final['Log_Return'].isna().sum()\n",
    "print(f'\\n3. NaN Returns Check:')\n",
    "print(f'   NaN values: {nan_returns}')\n",
    "print(f'   Status: {'Pass' if nan_returns == 0 else 'Warning'}')\n",
    "\n",
    "# Metadata completeness\n",
    "missing_sector = returns_final['Sector'].isna().sum()\n",
    "missing_beta = returns_final['Beta'].isna().sum()\n",
    "missing_group = returns_final['Beta_Group'].isna().sum()\n",
    "metadata_check = (missing_sector == 0) and (missing_beta == 0) and (missing_group == 0)\n",
    "print(f'\\n4. Metadata Completeness Check:')\n",
    "print(f'   Missing Sector: {missing_sector}')\n",
    "print(f'   Missing Beta: {missing_beta}')\n",
    "print(f'   Missing Beta_Group: {missing_group}')\n",
    "print(f'   Status: {'Pass' if metadata_check else 'Fail'}')\n",
    "\n",
    "# Beta group distribution\n",
    "beta_dist = returns_final.groupby('Ticker')['Beta_Group'].first().value_counts()\n",
    "print(f'\\n5. Beta Group Distribution:')\n",
    "print(beta_dist)\n",
    "balanced_check = (beta_dist['High Beta'] == 30) and (beta_dist['Low Beta'] == 30)\n",
    "print(f'   Status: {'Pass' if balanced_check else 'Warning'}')\n",
    "\n",
    "if all([ticker_check, inf_returns == 0, nan_returns == 0, metadata_check, balanced_check]):\n",
    "    print('\\nAll checks passed')\n",
    "else:\n",
    "    print('\\nValidation failed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OuQUbjfQEIje",
   "metadata": {
    "id": "OuQUbjfQEIje"
   },
   "source": [
    "### 5.2 Save Final Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "wJzFiQG4EOaJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1770953901866,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "wJzFiQG4EOaJ",
    "outputId": "296907a5-7a7f-4e2b-eaa4-420b8b58fd80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving datasets...\n",
      "\n",
      "News data → /content/drive/MyDrive/market-sentiment-impact-analysis/data/processed/daily_news_cleaned.csv\n",
      "Stock data → /content/drive/MyDrive/market-sentiment-impact-analysis/data/processed/stock_returns_60.csv\n"
     ]
    }
   ],
   "source": [
    "news_output_path = os.path.join(data_processed, 'daily_news_cleaned.csv')\n",
    "stock_output_path = os.path.join(data_processed, 'stock_returns_60.csv')\n",
    "\n",
    "print(f'Saving datasets...')\n",
    "print(f'\\nNews data → {news_output_path}')\n",
    "print(f'Stock data → {stock_output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "QM_5Kj6EEmei",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1456,
     "status": "ok",
     "timestamp": 1770953998225,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "QM_5Kj6EEmei",
    "outputId": "c9fb15d7-c234-45fb-d759-5f94af346eed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "News data saved\n",
      "  Records: 52,974\n",
      "  Columns: ['date', 'source', 'final_text']\n",
      "  File size: 12.29 MB\n"
     ]
    }
   ],
   "source": [
    "news_final.to_csv(news_output_path, index=False)\n",
    "\n",
    "print(f'\\nNews data saved')\n",
    "print(f'  Records: {len(news_final):,}')\n",
    "print(f'  Columns: {list(news_final.columns)}')\n",
    "print(f'  File size: {os.path.getsize(news_output_path) / 1024 / 1024:.2f} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sbbGv5bfE_Vs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 384,
     "status": "ok",
     "timestamp": 1770954003592,
     "user": {
      "displayName": "Sam Fan",
      "userId": "04882824446429076083"
     },
     "user_tz": 360
    },
    "id": "sbbGv5bfE_Vs",
    "outputId": "1eb0a472-87d7-4bfd-9325-a280ccc54821"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stock data saved\n",
      "  Records: 38,340\n",
      "  Columns: ['Date', 'Ticker', 'Log_Return', 'Sector', 'Beta', 'Beta_Group']\n",
      "  File size: 2.89 MB\n"
     ]
    }
   ],
   "source": [
    "returns_final.to_csv(stock_output_path, index=False)\n",
    "\n",
    "print(f'\\nStock data saved')\n",
    "print(f'  Records: {len(returns_final):,}')\n",
    "print(f'  Columns: {list(returns_final.columns)}')\n",
    "print(f'  File size: {os.path.getsize(stock_output_path) / 1024 / 1024:.2f} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ca4f1c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Data Quality & Distribution Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a40982",
   "metadata": {},
   "source": [
    "### A. News Dataset Characteristics\n",
    "The ingestion process successfully harmonized three disparate sources into a single timeline.\n",
    "- **Source Imbalance:** The final dataset is heavily skewed towards **Reuters (61.6%)** and **The Guardian (33.0%)**, with **CNBC (5.2%)** representing a minority of the corpus. This suggests that our sentiment signals will be primarily driven by wire-service style reporting (Reuters) rather than cable news commentary (CNBC).\n",
    "- **Deduplication:** We removed **111** duplicate headlines (0.21%), ensuring that repeated wire stories do not artificially amplify sentiment signals.\n",
    "- **Text Length:** The median text length is 248 characters, which is ideal for transformer models like FinBERT (need to be tested in the subsequent notebooks).\n",
    "\n",
    "### B. Stock Data Validation\n",
    "The retrieval of 60 stocks (30 High Beta / 30 Low Beta) confirms the structural integrity of our experimental groups.\n",
    "1. **Volatility Check:** The \"High Beta\" group exhibits an annualized volatility of **61.6%**, compared to just **29.1%** for the \"Low Beta\" group. This >2x difference confirms that we have successfully isolated two distinct risk regimes for testing.\n",
    "2. **Stationarity:** All price data has been converted to **Log Returns**, ensuring the target variable is stationary and suitable for the upcoming regression and causality tests.\n",
    "\n",
    "### C. Temporal Alignment\n",
    "- **News Range:** Jan 02, 2018 – July 18, 2020\n",
    "- **Stock Range:** Jan 03, 2018 – July 17, 2020\n",
    "- *Note:* The slight offset in start/end dates will be handled via an Inner Join in the final Analysis phase (Notebook 03), ensuring only days with both news and trading activity are modeled."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
